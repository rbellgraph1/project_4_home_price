{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required dependencies\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import psycopg2\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "pd.set_option('display.max_columns', 150, 'display.max_rows', 255)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_URI = 'postgresql://postgres:Masia0502@localhost:5432/home_price_post_db'\n",
    "connection = psycopg2.connect(DATABASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\AppData\\Local\\Temp\\ipykernel_14528\\4183198285.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {table_name}\", connection)\n"
     ]
    }
   ],
   "source": [
    "# Replace 'table_name' with the name of the table you want to import\n",
    "table_name = 'post_home_prices_allcolumn'\n",
    "\n",
    "# Use the 'pandas.read_sql()' function to import the table into a DataFrame\n",
    "df = pd.read_sql(f\"SELECT * FROM {table_name}\", connection)\n",
    "\n",
    "# Close the database connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a copy of the dataframe to use in neural networks\n",
    "# nn_df = df.copy()\n",
    "# # nn_df = nn_df.drop(columns=['Neighborhood'])\n",
    "# nn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # nn_df = nn_df.drop(columns='Id', axis=1)\n",
    "# nn_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X_moons, y_moons, random_state\u001b[39m=\u001b[39m\u001b[39m78\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39m# Create scaler instance\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m X_scaler \u001b[39m=\u001b[39m skl\u001b[39m.\u001b[39mpreprocessing\u001b[39m.\u001b[39mStandardScaler()\n\u001b[0;32m     18\u001b[0m \u001b[39m# Fit the scaler\u001b[39;00m\n\u001b[0;32m     19\u001b[0m X_scaler\u001b[39m.\u001b[39mfit(X_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'skl' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating dummy nonlinear data\n",
    "X_moons, y_moons = make_moons(n_samples=1000, noise=0.08, random_state=78)\n",
    "\n",
    "# Transforming y_moons to a vertical vector\n",
    "y_moons = y_moons.reshape(-1, 1)\n",
    "\n",
    "# Creating a DataFrame to plot the nonlinear dummy data\n",
    "df_moons = pd.DataFrame(X_moons, columns=[\"Feature 1\", \"Feature 2\"])\n",
    "df_moons[\"Target\"] = y_moons\n",
    "\n",
    "# Use sklearn to split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_moons, y_moons, random_state=78)\n",
    "\n",
    "# Create scaler instance\n",
    "X_scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RUTDataViz2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
